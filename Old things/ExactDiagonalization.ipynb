{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d896ed0-9425-43a3-87d1-36037bea5dfd",
   "metadata": {},
   "source": [
    "# AMDGPU Code\n",
    "\n",
    "This is created for version 1.11+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9171b550-d544-4867-9a83-2f462af44f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Version 1.11.1\n",
      "Commit 8f5b7ca12ad (2024-10-16 10:53 UTC)\n",
      "Build Info:\n",
      "  Official https://julialang.org/ release\n",
      "Platform Info:\n",
      "  OS: macOS (x86_64-apple-darwin22.4.0)\n",
      "  CPU: 16 × Intel(R) Core(TM) i9-9880H CPU @ 2.30GHz\n",
      "  WORD_SIZE: 64\n",
      "  LLVM: libLLVM-16.0.6 (ORCJIT, skylake)\n",
      "Threads: 4 default, 0 interactive, 2 GC (on 16 virtual cores)\n",
      "Environment:\n",
      "  JULIA_NUM_THREADS = 4\n"
     ]
    }
   ],
   "source": [
    "versioninfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2061add-a207-41c0-b6de-0f82b1ebeeae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "# For installing\n",
    "using Pkg\n",
    "#Pkg.add(\"AMDGPU\")\n",
    "Pkg.update(\"AMDGPU\")\n",
    "#println(\"AMDGPU Installed\")\n",
    "\n",
    "Pkg.add(\"BenchmarkTools\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ab4a07-524d-4db5-945a-41f7379225bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fa36fae-feac-4719-b83f-6f7b12034c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───────────┬──────────────────┬─────────┬───────────────────────────────────────────────────────────────────────────────────────────┐\n",
      "│\u001b[1m Available \u001b[0m│\u001b[1m Name             \u001b[0m│\u001b[1m Version \u001b[0m│\u001b[1m Path                                                                                      \u001b[0m│\n",
      "├───────────┼──────────────────┼─────────┼───────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│     +     │ LLD              │ -       │ /Applications/Julia-1.11.app/Contents/Resources/julia/libexec/julia/lld                   │\n",
      "│     +     │ Device Libraries │ -       │ /Users/josephlee/.julia/artifacts/5ad5ecb46e3c334821f54c1feecc6c152b7b6a45/amdgcn/bitcode │\n",
      "│     -     │ HIP              │ -       │ -                                                                                         │\n",
      "│     -     │ rocBLAS          │ -       │ -                                                                                         │\n",
      "│     -     │ rocSOLVER        │ -       │ -                                                                                         │\n",
      "│     -     │ rocALUTION       │ -       │ -                                                                                         │\n",
      "│     -     │ rocSPARSE        │ -       │ -                                                                                         │\n",
      "│     -     │ rocRAND          │ -       │ -                                                                                         │\n",
      "│     -     │ rocFFT           │ -       │ -                                                                                         │\n",
      "│     -     │ MIOpen           │ -       │ -                                                                                         │\n",
      "└───────────┴──────────────────┴─────────┴───────────────────────────────────────────────────────────────────────────────────────────┘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mAMDGPU versioninfo\n"
     ]
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "using AMDGPU\n",
    "using Test\n",
    "using BenchmarkTools\n",
    "\n",
    "AMDGPU.versioninfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f556b74c-9e62-445c-9acd-091350eebf93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31564085-a80e-49d4-9d2b-f3220a7b1a0b",
   "metadata": {},
   "source": [
    "First, let's talk about some coding practices:\n",
    "- function names that end with an exclamation mark modify one or more of their arguments by convention\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522d4246-4182-4e35-a688-e48914204ddb",
   "metadata": {},
   "source": [
    "# Matrix Multiplication\n",
    "\n",
    "We will start with the same example that I did in CUDA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06b18a22-de1a-4530-b091-ce2005cca32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fast_matmul! (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fast matrix multiplication function using BLAS\n",
    "function fast_matmul!(C, A, B)\n",
    "    # C should be initialized to the correct size before calling this function\n",
    "    mul!(C, A, B) # mul! is from the BLAS.  # As an aside, I *think* A*B calls on BLAS functions\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153ea30e-55ea-4850-b8bf-843fe1435260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4521066-8940-46ca-85d1-335e3d28558e",
   "metadata": {},
   "outputs": [],
   "source": [
    "testMat = rand(100, 500)\n",
    "println(\"here\")\n",
    "testMat_d = ROCArray(testMat)\n",
    "size(testMat_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ca2f77df-48d6-41a7-85ce-f6497aa513b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000×2000 Matrix{Float64}:\n",
       " 122.085  124.367  117.955  120.673  …  127.311  120.176  121.221  122.627\n",
       " 131.479  134.291  125.347  127.901     137.384  128.11   130.163  135.986\n",
       " 126.807  132.284  128.902  128.195     135.742  128.342  127.904  134.684\n",
       " 117.003  124.505  120.232  119.494     125.956  118.821  121.383  121.224\n",
       " 124.39   128.686  126.833  129.858     132.027  126.384  126.725  126.692\n",
       " 123.08   130.885  127.633  125.086  …  131.579  123.411  127.739  130.459\n",
       " 126.205  132.3    124.283  126.624     131.724  122.261  125.053  128.263\n",
       " 118.929  128.073  122.211  122.838     126.123  117.958  121.699  122.888\n",
       " 127.475  130.564  126.832  126.9       134.415  126.276  127.594  130.587\n",
       " 124.114  128.297  126.935  127.506     134.641  124.337  126.549  130.273\n",
       " 123.511  126.602  124.143  123.982  …  131.309  121.829  126.413  123.99\n",
       " 124.013  133.116  124.904  126.222     135.304  129.072  127.561  129.111\n",
       " 123.573  129.263  124.519  125.532     133.499  123.283  125.155  126.69\n",
       "   ⋮                                 ⋱                             \n",
       " 114.536  123.398  120.25   123.674     127.399  119.039  118.732  121.411\n",
       " 126.731  134.555  129.201  132.08      139.373  127.506  129.63   133.586\n",
       " 131.066  131.964  130.675  128.311  …  135.347  125.33   130.39   131.582\n",
       " 120.739  130.018  124.448  124.227     131.602  122.267  126.126  126.574\n",
       " 123.039  132.214  130.124  130.001     137.363  126.687  130.908  131.551\n",
       " 126.316  130.87   126.278  126.835     130.615  120.811  125.538  128.085\n",
       " 114.894  122.716  116.598  117.541     129.494  115.536  119.37   123.577\n",
       " 124.081  125.126  124.458  128.694  …  132.555  124.434  122.282  128.407\n",
       " 127.054  127.274  121.35   128.483     132.642  123.817  128.136  124.046\n",
       " 122.042  130.096  122.478  123.172     132.149  125.043  123.959  127.262\n",
       " 127.097  136.243  130.407  130.779     138.23   129.403  126.329  132.619\n",
       " 123.008  128.85   123.82   129.545     132.444  123.357  126.645  126.144"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = rand(1000, 500)  # Generate a random 1000x500 matrix\n",
    "B = rand(500, 2000)  # Generate a random 500x2000 matrix\n",
    "C = zeros(1000, 2000)\n",
    "println(sum(C))\n",
    "# Perform matrix multiplication on the GPU\n",
    "fast_matmul!(C, A, B)\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4170559-729f-4e06-b8f5-64c6c2296d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Matmul_AMDGPU! (generic function with 1 method)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to perform matrix multiplication on the GPU\n",
    "function kernel_Matmul_ADMGPU!(C, A, B, M, N, K)\n",
    "    \"\"\"\n",
    "    Kernel function for the AMD GPU.\n",
    "    A has dimensions M x K, and B has dimensions K x N\n",
    "    \"\"\"\n",
    "    for i in 1:M\n",
    "        for j in 1:N\n",
    "            value = 0.0\n",
    "            for k in 1:K\n",
    "                value += A[i, k] * B[k, j]\n",
    "            end\n",
    "            C[i, j] = value\n",
    "        end\n",
    "    end\n",
    "    return\n",
    "end\n",
    "\n",
    "\n",
    "# Wrapper function for the GPU code\n",
    "function Matmul_AMDGPU!(C_d, A_d, B_d)\n",
    "    \"\"\"\n",
    "  \n",
    "    \"\"\"\n",
    "    # Check if dimensions are compatible\n",
    "    if size(A, 2) != size(B, 1) # compares the 2nd dimension of A and the first dimension of B\n",
    "        throw(ArgumentError(\"Inner dimensions must match for multiplication.\"))\n",
    "    end\n",
    "    \n",
    "    M, K = size(A_d)\n",
    "    K, N = size(B_d)\n",
    "    #println(M, K, N)\n",
    "    \n",
    "    groupsize = 256\n",
    "    gridsize = 4\n",
    "    @roc groupsize=groupszie gridsize=gridsize kernel_Matmul_ADMGPU!(C_d, A_d, B_d, M, N, K)\n",
    "    #println(\"Here\")\n",
    "    # Wait for the kernel to finish\n",
    "    #AMDGPU.synchronize()\n",
    "    return \n",
    "end\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1919e980-193e-4f7e-a472-9b03250e2462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cld(1024, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "661a1593-1c0b-4690-812d-64cfc729b81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The benchmarking (fast mul): \n",
      "  25.495 ms (0 allocations: 0 bytes)\n",
      "\n",
      "Benchmarking GPU code\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "could not load library \"\"\ndlopen(.dylib, 0x0001): tried: '/Applications/Julia-1.11.app/Contents/Resources/julia/lib/julia/.dylib' (no such file), '/Applications/Julia-1.11.app/Contents/Resources/julia/lib/julia/../.dylib' (no such file), '/Applications/Julia-1.11.app/Contents/Resources/julia/bin/../lib/.dylib' (no such file), '.dylib' (no such file), '/usr/local/lib/.dylib' (no such file), '/usr/lib/.dylib' (no such file), '/Users/josephlee/Julia Code/Github-Repos/algorithms/.dylib' (no such file)",
     "output_type": "error",
     "traceback": [
      "could not load library \"\"\ndlopen(.dylib, 0x0001): tried: '/Applications/Julia-1.11.app/Contents/Resources/julia/lib/julia/.dylib' (no such file), '/Applications/Julia-1.11.app/Contents/Resources/julia/lib/julia/../.dylib' (no such file), '/Applications/Julia-1.11.app/Contents/Resources/julia/bin/../lib/.dylib' (no such file), '.dylib' (no such file), '/usr/local/lib/.dylib' (no such file), '/usr/lib/.dylib' (no such file), '/Users/josephlee/Julia Code/Github-Repos/algorithms/.dylib' (no such file)",
      "",
      "Stacktrace:",
      "  [1] macro expansion",
      "    @ ~/.julia/packages/AMDGPU/Debbg/src/hip/call.jl:38 [inlined]",
      "  [2] macro expansion",
      "    @ ~/.julia/packages/AMDGPU/Debbg/src/utils.jl:138 [inlined]",
      "  [3] hipDeviceGet(device::Base.RefValue{Ptr{Nothing}}, ordinal::Int64)",
      "    @ AMDGPU.HIP ~/.julia/packages/AMDGPU/Debbg/src/hip/libhip.jl:14",
      "  [4] HIPDevice(device_id::Int64)",
      "    @ AMDGPU.HIP ~/.julia/packages/AMDGPU/Debbg/src/hip/device.jl:15",
      "  [5] TaskLocalState",
      "    @ ~/.julia/packages/AMDGPU/Debbg/src/tls.jl:11 [inlined]",
      "  [6] #36",
      "    @ ~/.julia/packages/AMDGPU/Debbg/src/tls.jl:27 [inlined]",
      "  [7] get!(default::AMDGPU.var\"#36#37\"{Tuple{}}, d::IdDict{Any, Any}, key::Any)",
      "    @ Base ./iddict.jl:171",
      "  [8] task_local_state!()",
      "    @ AMDGPU ~/.julia/packages/AMDGPU/Debbg/src/tls.jl:26",
      "  [9] device",
      "    @ ~/.julia/packages/AMDGPU/Debbg/src/tls.jl:35 [inlined]",
      " [10] macro expansion",
      "    @ ~/.julia/packages/AMDGPU/Debbg/src/compiler/codegen.jl:156 [inlined]",
      " [11] macro expansion",
      "    @ ./lock.jl:273 [inlined]",
      " [12] hipfunction(f::typeof(kernel_Matmul_ADMGPU!), tt::Type{Tuple{Matrix{Float32}, Matrix{Float32}, Matrix{Float32}, Int64, Int64, Int64}}; kwargs::@Kwargs{})",
      "    @ AMDGPU.Compiler ~/.julia/packages/AMDGPU/Debbg/src/compiler/codegen.jl:155",
      " [13] hipfunction",
      "    @ ~/.julia/packages/AMDGPU/Debbg/src/compiler/codegen.jl:154 [inlined]",
      " [14] macro expansion",
      "    @ ~/.julia/packages/AMDGPU/Debbg/src/highlevel.jl:153 [inlined]",
      " [15] Matmul_AMDGPU!(C_d::Matrix{Float32}, A_d::Matrix{Float32}, B_d::Matrix{Float32})",
      "    @ Main ./In[21]:36",
      " [16] var\"##core#288\"()",
      "    @ Main ~/.julia/packages/BenchmarkTools/QNsku/src/execution.jl:561",
      " [17] var\"##sample#289\"(::Tuple{}, __params::BenchmarkTools.Parameters)",
      "    @ Main ~/.julia/packages/BenchmarkTools/QNsku/src/execution.jl:570",
      " [18] _lineartrial(b::BenchmarkTools.Benchmark, p::BenchmarkTools.Parameters; maxevals::Int64, kwargs::@Kwargs{})",
      "    @ BenchmarkTools ~/.julia/packages/BenchmarkTools/QNsku/src/execution.jl:187",
      " [19] _lineartrial(b::BenchmarkTools.Benchmark, p::BenchmarkTools.Parameters)",
      "    @ BenchmarkTools ~/.julia/packages/BenchmarkTools/QNsku/src/execution.jl:182",
      " [20] #invokelatest#2",
      "    @ ./essentials.jl:1055 [inlined]",
      " [21] invokelatest",
      "    @ ./essentials.jl:1052 [inlined]",
      " [22] #lineartrial#46",
      "    @ ~/.julia/packages/BenchmarkTools/QNsku/src/execution.jl:51 [inlined]",
      " [23] lineartrial",
      "    @ ~/.julia/packages/BenchmarkTools/QNsku/src/execution.jl:50 [inlined]",
      " [24] tune!(b::BenchmarkTools.Benchmark, p::BenchmarkTools.Parameters; progressid::Nothing, nleaves::Float64, ndone::Float64, verbose::Bool, pad::String, kwargs::@Kwargs{})",
      "    @ BenchmarkTools ~/.julia/packages/BenchmarkTools/QNsku/src/execution.jl:300",
      " [25] tune!",
      "    @ ~/.julia/packages/BenchmarkTools/QNsku/src/execution.jl:289 [inlined]",
      " [26] tune!(b::BenchmarkTools.Benchmark)",
      "    @ BenchmarkTools ~/.julia/packages/BenchmarkTools/QNsku/src/execution.jl:289",
      " [27] top-level scope",
      "    @ ~/.julia/packages/BenchmarkTools/QNsku/src/execution.jl:666"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "M, K, N = 2048, 2048, 2048\n",
    "A = rand(Float32, M, K);\n",
    "B = rand(Float32, K, N);\n",
    "C = zeros(Float32, M, N);\n",
    "println(\"The benchmarking (fast mul): \");\n",
    "@btime fast_matmul!(C, A, B);\n",
    "println()\n",
    "\n",
    "C2 = zeros(Float32, M, N);\n",
    "\n",
    "A_d = AMDGPU.Array(A)\n",
    "B_d = AMDGPU.Array(B)\n",
    "C2_d = AMDGPU.Array(C2)\n",
    "# Perform matrix multiplication on the GPU\n",
    "println(\"Benchmarking GPU code\")\n",
    "@btime Matmul_AMDGPU!(C2_d, A_d, B_d)\n",
    "println(\"-Comment out if you want to see the resulting matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d11fd89-df02-455d-a617-b33d1504d5af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829f04ef-f564-4534-96b1-567499ab1afd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42022f81-e07c-4b88-ae66-9754d2435bca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7458ec-39e8-4d9a-bd5b-8d5c0e3fe7d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia (4 threads) 1.11.1",
   "language": "julia",
   "name": "julia-_4-threads_-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
